{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3cWcfWvwfSU",
        "outputId": "26264e16-9dc0-4ea2-bdd4-48f470ba894e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting taming-transformers-rom1504\n",
            "  Using cached taming_transformers_rom1504-0.0.6-py3-none-any.whl.metadata (406 bytes)\n",
            "Collecting torch (from taming-transformers-rom1504)\n",
            "  Using cached torch-2.8.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision (from taming-transformers-rom1504)\n",
            "  Using cached torchvision-0.23.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from taming-transformers-rom1504) (1.25.0)\n",
            "Requirement already satisfied: tqdm in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from taming-transformers-rom1504) (4.67.1)\n",
            "Collecting omegaconf>=2.0.0 (from taming-transformers-rom1504)\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-lightning>=1.0.8 (from taming-transformers-rom1504)\n",
            "  Using cached pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0.0->taming-transformers-rom1504)\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from omegaconf>=2.0.0->taming-transformers-rom1504) (6.0)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (2025.7.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning>=1.0.8->taming-transformers-rom1504)\n",
            "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch-lightning>=1.0.8->taming-transformers-rom1504) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch-lightning>=1.0.8->taming-transformers-rom1504) (4.14.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.0.8->taming-transformers-rom1504)\n",
            "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (3.10)\n",
            "Requirement already satisfied: setuptools in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504) (67.8.0)\n",
            "Collecting filelock (from torch->taming-transformers-rom1504)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->taming-transformers-rom1504)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch->taming-transformers-rom1504) (3.2)\n",
            "Requirement already satisfied: jinja2 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch->taming-transformers-rom1504) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->taming-transformers-rom1504)\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch->taming-transformers-rom1504)\n",
            "  Using cached triton-3.4.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: importlib-metadata in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from triton==3.4.0->torch->taming-transformers-rom1504) (6.0.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->taming-transformers-rom1504)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch->taming-transformers-rom1504) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from jinja2->torch->taming-transformers-rom1504) (2.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torchvision->taming-transformers-rom1504) (9.4.0)\n",
            "Using cached taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Using cached pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
            "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Using cached torch-2.8.0-cp39-cp39-manylinux_2_28_x86_64.whl (888.0 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.4.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached torchvision-0.23.0-cp39-cp39-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, antlr4-python3-runtime, sympy, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, filelock, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchmetrics, pytorch-lightning, taming-transformers-rom1504\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [taming-transformers-rom1504]ghtning]12]2]\n",
            "\u001b[1A\u001b[2KSuccessfully installed antlr4-python3-runtime-4.9.3 filelock-3.19.1 lightning-utilities-0.15.2 mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 omegaconf-2.3.0 pytorch-lightning-2.5.6 sympy-1.14.0 taming-transformers-rom1504-0.0.6 torch-2.8.0 torchmetrics-1.8.2 torchvision-0.23.0 triton-3.4.0\n",
            "Requirement already satisfied: pytorch_lightning in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (2.5.6)\n",
            "Requirement already satisfied: torch>=2.1.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.7.0)\n",
            "Requirement already satisfied: torchmetrics>0.7.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (4.14.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from pytorch_lightning) (0.15.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: setuptools in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (67.8.0)\n",
            "Requirement already satisfied: filelock in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (3.2)\n",
            "Requirement already satisfied: jinja2 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torch>=2.1.0->pytorch_lightning) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from triton==3.4.0->torch>=2.1.0->pytorch_lightning) (6.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from torchmetrics>0.7.0->pytorch_lightning) (1.25.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch>=2.1.0->pytorch_lightning) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gil/anaconda3/envs/YS_pt2/lib/python3.9/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/simulamet-host/conditional-polyp-diffusion.git\n",
        "!pip install taming-transformers-rom1504\n",
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fWQ9xjCN3qKH"
      },
      "outputs": [],
      "source": [
        "from ldm.models.autoencoder import VQModel\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os, cv2, random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pytorch_lightning.trainer import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from torchvision import transforms\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ZPvWxERxjB0"
      },
      "outputs": [],
      "source": [
        "# Setting params for VQVAE\n",
        "ddconfig ={\n",
        "        \"double_z\": False,\n",
        "        \"z_channels\": 3,\n",
        "        \"resolution\": 256,\n",
        "        \"in_channels\": 3,\n",
        "        \"out_ch\":3,\n",
        "        \"ch\":128,\n",
        "        \"ch_mult\":[1, 2, 4],\n",
        "        \"num_res_blocks\":2,\n",
        "        \"attn_resolutions\":[],\n",
        "        \"dropout\":0.0\n",
        "}\n",
        "lossconfig = {\n",
        "    \"target\": \"taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator\",\n",
        "    \"params\": {\n",
        "        \"disc_conditional\": False,\n",
        "        \"disc_in_channels\": 3,\n",
        "        \"disc_start\": 0,\n",
        "        \"disc_weight\": 0.75,\n",
        "        \"codebook_weight\": 1.0\n",
        "    }\n",
        "}\n",
        "dataconfig = {\n",
        "      \"batch_size\": 1,\n",
        "      \"num_workers\": 4,\n",
        "      \"path\": \"../../../01_data/02_preproc/02_abnormal/P2/images\", # image path\n",
        "      \"size\": 512,\n",
        "}\n",
        "\n",
        "n_embed = 8192\n",
        "embed_dim = 3\n",
        "\n",
        "# pretrained model path\n",
        "ckpt_path = \"../../../03_model/model.ckpt\"\n",
        "# saving ckpt path\n",
        "saving_ckpt_path = \"../../../03_model/abnormal/P2/vqvae/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qouXDLlhZxfa"
      },
      "outputs": [],
      "source": [
        "class InpaintingTrain_autoencoder(Dataset):\n",
        "    def __init__(self, size, data_root, config=None):\n",
        "        self.size = size\n",
        "        self.config = config\n",
        "        self.data_root=data_root\n",
        "        self.images = [img for img in os.listdir(data_root) if img.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "\n",
        "    def generate_stroke_mask(self, im_size, parts=15, maxVertex=25, maxLength=80, maxBrushWidth=60, maxAngle=360):\n",
        "\n",
        "        mask = np.zeros((im_size[0], im_size[1], 1), dtype=np.float32)\n",
        "        for i in range(parts):\n",
        "            mask = mask + self.np_free_form_mask(maxVertex, maxLength, maxBrushWidth, maxAngle, im_size[0], im_size[1])\n",
        "        mask = np.minimum(mask, 1.0)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def np_free_form_mask(self, maxVertex, maxLength, maxBrushWidth, maxAngle, h, w):\n",
        "\n",
        "        mask = np.zeros((h, w, 1), np.float32)\n",
        "        numVertex = np.random.randint(maxVertex + 1)\n",
        "        startY = np.random.randint(h)\n",
        "        startX = np.random.randint(w)\n",
        "        brushWidth = 0\n",
        "        for i in range(numVertex):\n",
        "            angle = np.random.randint(maxAngle + 1)\n",
        "            angle = angle / 360.0 * 2 * np.pi\n",
        "            if i % 2 == 0:\n",
        "                angle = 2 * np.pi - angle\n",
        "            length = np.random.randint(maxLength + 1)\n",
        "            brushWidth = np.random.randint(10, maxBrushWidth + 1) // 2 * 2\n",
        "            nextY = startY + length * np.cos(angle)\n",
        "            nextX = startX + length * np.sin(angle)\n",
        "            nextY = np.maximum(np.minimum(nextY, h - 1), 0).astype(int)\n",
        "            nextX = np.maximum(np.minimum(nextX, w - 1), 0).astype(int)\n",
        "            cv2.line(mask, (startY, startX), (nextY, nextX), 1, brushWidth)\n",
        "            cv2.circle(mask, (startY, startX), brushWidth // 2, 2)\n",
        "            startY, startX = nextY, nextX\n",
        "        cv2.circle(mask, (startY, startX), brushWidth // 2, 2)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        image = np.array(Image.open(self.data_root+\"/\"+self.images[i]).convert(\"RGB\").resize((self.size,self.size)))\n",
        "        image = image.astype(np.float32) / 255.0#\n",
        "        # image = image[None].transpose(0,3,1,2)\n",
        "        image = torch.from_numpy(image)\n",
        "        mask = self.generate_stroke_mask([self.size, self.size])\n",
        "        mask[mask < 0.5] = 0\n",
        "        mask[mask >= 0.5] = 1\n",
        "        # mask = mask[None].transpose(0,3,1,2)\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        masked_image = (1 - mask) * image\n",
        "\n",
        "        ##50% chance to return a masked_image instead of the original image.\n",
        "        if random.uniform(0, 1)<0.5:\n",
        "            batch = {\"image\": np.squeeze(image,0), \"masked_image\": np.squeeze(masked_image,0)}\n",
        "        else:\n",
        "            batch = {\"masked_image\": np.squeeze(image,0), \"image\": np.squeeze(masked_image,0)}\n",
        "\n",
        "        batch = {\"image\": np.squeeze(image,0), \"masked_image\": np.squeeze(masked_image,0)}\n",
        "        for k in batch:\n",
        "            batch[k] = batch[k] * 2.0 - 1.0\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiJozptM-SKE",
        "outputId": "4cfcff6b-cbdf-4cb9-c4c2-8753b216ae16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored from ../../../03_model/model.ckpt with 0 missing and 0 unexpected keys\n"
          ]
        }
      ],
      "source": [
        "model = VQModel(ddconfig, lossconfig, n_embed=n_embed, embed_dim=embed_dim, ckpt_path=ckpt_path)\n",
        "# Create a ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=saving_ckpt_path,  # Directory to save checkpoints\n",
        "    filename='VQVAE-{epoch:02d}',  # Filename format\n",
        "    monitor='train/total_loss',  # Metric to monitor\n",
        "    mode='min',          # Mode for monitoring ('min' or 'max')\n",
        "    save_top_k=3         # Number of top models to save\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=1000,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sBYFz8pk_OMY"
      },
      "outputs": [],
      "source": [
        "data = InpaintingTrain_autoencoder(dataconfig[\"size\"], dataconfig[\"path\"])\n",
        "data = DataLoader(data,\n",
        "                batch_size=dataconfig[\"batch_size\"],\n",
        "                shuffle=True,\n",
        "                num_workers=dataconfig[\"num_workers\"],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "8fd9c98bfdbc45dfbb7122c0923fc319",
            "7b86fc9eb7a64386bb65f84c6273b930",
            "db8d65fad26a4df0a84d4e17bc21f41e",
            "eaee5d659711418bbb8392a5273d1369",
            "14f362b1a5224c0a842261304624c8d0",
            "613f531afbaa4ce0834d99cf09a3e587",
            "000c98545a7f417f971780c86d0f7c75",
            "13ca60aff88f42ce84187d40a216e23d",
            "a1fce4b39a7b4e4381e9faf0d6748b6b",
            "f004593ccf5540a7a4426d30294dce54",
            "ef954501f13849ff80da34d66e7a4e5d"
          ]
        },
        "id": "zCINAHDR8ocw",
        "outputId": "e71a2a55-218e-44c5-bea9-5a35fd363f95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gil/anaconda3/envs/YS_pt/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type                     | Params | Mode \n",
            "---------------------------------------------------------------------\n",
            "0 | encoder         | Encoder                  | 22.3 M | train\n",
            "1 | decoder         | Decoder                  | 33.0 M | train\n",
            "2 | loss            | VQLPIPSWithDiscriminator | 17.5 M | train\n",
            "3 | quantize        | VectorQuantizer2         | 24.6 K | train\n",
            "4 | quant_conv      | Conv2d                   | 12     | train\n",
            "5 | post_quant_conv | Conv2d                   | 12     | train\n",
            "---------------------------------------------------------------------\n",
            "58.1 M    Trainable params\n",
            "14.7 M    Non-trainable params\n",
            "72.8 M    Total params\n",
            "291.218   Total estimated model params size (MB)\n",
            "187       Modules in train mode\n",
            "58        Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr_d 4.5e-06\n",
            "lr_g 4.5e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gil/anaconda3/envs/YS_pt/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 58 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a49848de506743ba8bd8c8ed44d48294",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
          ]
        }
      ],
      "source": [
        "model.learning_rate = 4.5e-06\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "YS_pt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "000c98545a7f417f971780c86d0f7c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ca60aff88f42ce84187d40a216e23d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f362b1a5224c0a842261304624c8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "613f531afbaa4ce0834d99cf09a3e587": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b86fc9eb7a64386bb65f84c6273b930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613f531afbaa4ce0834d99cf09a3e587",
            "placeholder": "​",
            "style": "IPY_MODEL_000c98545a7f417f971780c86d0f7c75",
            "value": "Epoch 0:  20%"
          }
        },
        "8fd9c98bfdbc45dfbb7122c0923fc319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b86fc9eb7a64386bb65f84c6273b930",
              "IPY_MODEL_db8d65fad26a4df0a84d4e17bc21f41e",
              "IPY_MODEL_eaee5d659711418bbb8392a5273d1369"
            ],
            "layout": "IPY_MODEL_14f362b1a5224c0a842261304624c8d0"
          }
        },
        "a1fce4b39a7b4e4381e9faf0d6748b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db8d65fad26a4df0a84d4e17bc21f41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ca60aff88f42ce84187d40a216e23d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1fce4b39a7b4e4381e9faf0d6748b6b",
            "value": 20
          }
        },
        "eaee5d659711418bbb8392a5273d1369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f004593ccf5540a7a4426d30294dce54",
            "placeholder": "​",
            "style": "IPY_MODEL_ef954501f13849ff80da34d66e7a4e5d",
            "value": " 20/100 [00:09&lt;00:37,  2.11it/s, v_num=18]"
          }
        },
        "ef954501f13849ff80da34d66e7a4e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f004593ccf5540a7a4426d30294dce54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
