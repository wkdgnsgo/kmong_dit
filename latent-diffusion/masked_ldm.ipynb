{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN2hoxzSJ6Zu",
        "outputId": "9ea92e3d-deb1-4302-c7ba-583ec288fd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kmong_dit'...\n",
            "remote: Enumerating objects: 2519, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 2519 (delta 14), reused 13 (delta 9), pack-reused 2489 (from 4)\u001b[K\n",
            "Receiving objects: 100% (2519/2519), 85.75 MiB | 13.83 MiB/s, done.\n",
            "Resolving deltas: 100% (440/440), done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wkdgnsgo/kmong_dit.git\n",
        "!pip install -q omegaconf\n",
        "!pip install -q pytorch-lightning\n",
        "!pip install -q taming-transformers-rom1504\n",
        "!pip install -q kornia\n",
        "!pip install -q openai-clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS1kay5PKsD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b86a8c-14ab-4527-8dbf-583d91ca9776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from omegaconf import OmegaConf\n",
        "import os, sys, datetime, glob, importlib, csv\n",
        "import random\n",
        "import torch\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# import sys, types\n",
        "# mpi4py = types.ModuleType(\"mpi4py\")\n",
        "# class _DummyComm:\n",
        "#     def Get_size(self): return 1\n",
        "#     def Get_rank(self): return 0\n",
        "#     def bcast(self, x, root=0): return x\n",
        "# class _DummyMPI: COMM_WORLD = _DummyComm()\n",
        "# mpi4py.MPI = _DummyMPI()\n",
        "# sys.modules[\"mpi4py\"] = mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pQHMlN3nMA6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0832dcd8-4e64-4654-d419-372d61fca06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQiwY3IRLTaZ"
      },
      "outputs": [],
      "source": [
        "#unet_config:\n",
        "# params:\n",
        "#         image_size: 128\n",
        "#         in_channels: 6\n",
        "#         out_channels: 3\n",
        "#         model_channels: 128\n",
        "#         attention_resolutions:\n",
        "#         - 32\n",
        "#         - 16\n",
        "#         - 8\n",
        "#         num_res_blocks: 2\n",
        "#         channel_mult:\n",
        "#         - 1\n",
        "#         - 4\n",
        "#         - 8\n",
        "# data:\n",
        "#  train:\n",
        "#       target: ldm.data.kvasir.KvasirSegTrain\n",
        "#       params:\n",
        "#         size: 512\n",
        "#     validation:\n",
        "#       target: ldm.data.kvasir.KvasirSegEval\n",
        "#       params:\n",
        "#         size: 512\n",
        "\n",
        "configs = [OmegaConf.load(cfg) for cfg in [\"/content/kmong_dit/latent-diffusion/configs/latent-diffusion/kvasir-flow-matching.yaml\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58gML3RSZpun"
      },
      "outputs": [],
      "source": [
        "# data_train.txt, data_eval.txt 가 존재하지 않는다면, 이 cell을 실행해서 생성해야됌\n",
        "data_root = \"/content/drive/MyDrive/01_data/\"\n",
        "data_set_name = \"\"\n",
        "\n",
        "data_path = os.path.join(data_root, data_set_name, \"images\")\n",
        "\n",
        "def create_data_csv(data_path, ratio=0.8):\n",
        "    data_list = os.listdir(data_path)\n",
        "    random.shuffle(data_list)\n",
        "    train_list = data_list[:int(len(data_list)*ratio)]\n",
        "    test_list = data_list[int(len(data_list)*ratio):]\n",
        "\n",
        "    with open(os.path.join(\"/content/drive/MyDrive/01_data/\", \"data_train.txt\"), \"w\") as f: # path\n",
        "        for item in train_list:\n",
        "            f.write(item+\"\\n\")\n",
        "\n",
        "    with open(os.path.join(\"/content/drive/MyDrive/01_data/\", \"data_eval.txt\"), \"w\") as f: # path\n",
        "        for item in test_list:\n",
        "            f.write(item+\"\\n\")\n",
        "\n",
        "create_data_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6j4_623cMyw"
      },
      "outputs": [],
      "source": [
        "# latent-diffusion/ldm/data/kvasir에서 KvasirSegTrain와 KvasirSegEval 수정\n",
        "\n",
        "# class KvasirSegTrain(SegmentationBase):\n",
        "#     def __init__(self, size=None, random_crop=False, interpolation=\"bicubic\"):\n",
        "#         super().__init__(data_csv='/content/data_train.txt', # data_train.txt가 있는 위치 수정\n",
        "#                          data_root='/content/drive/MyDrive/velum/images', # 데이터 있는 위치로 수정\n",
        "#                          segmentation_root='/content/drive/MyDrive/velum/masks', # 데이터 있는 위치로 수정\n",
        "#                          size=size, random_crop=random_crop, interpolation=interpolation,\n",
        "#                          n_labels=2)\n",
        "\n",
        "# class KvasirSegEval(SegmentationBase):\n",
        "#     def __init__(self, size=None, random_crop=False, interpolation=\"bicubic\"):\n",
        "#         super().__init__(data_csv='/content/data_eval.txt', # data_eval.txt가 있는 위치로 수정\n",
        "#                          data_root='/content/drive/MyDrive/velum/images', # 데이터 있는 위치로 수정\n",
        "#                          segmentation_root='/content/drive/MyDrive/velum/masks', # 데이터 있는 위치로 수정\n",
        "#                          size=size, random_crop=random_crop, interpolation=interpolation,\n",
        "#                          n_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzgnrinlKoIi",
        "outputId": "30930264-ec5c-4b61-a600-dba5612efe1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd kmong_dit/latent-diffusion/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NXX63OWNPtX",
        "outputId": "d911f2c5-619f-48fe-9551-0718b50f7d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kmong_dit/latent-diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU4RJdBTKCd3",
        "outputId": "e9dd2f2e-53e6-4d53-cd66-53521172b438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 3, 128, 128) = 49152 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Restored from /content/drive/MyDrive/VQVAE-epoch=105.ckpt with 0 missing and 55 unexpected keys\n"
          ]
        }
      ],
      "source": [
        "# from conditional-polyp-diffusion/latent-diffusion/ldm/models/diffusion/ddpm.py 교체\n",
        "# main.py 파일 17번째 줄 아래와 같이 수정\n",
        "# from pytorch_lightning.utilities import rank_zero_only\n",
        "from ldm.util import instantiate_from_config\n",
        "from pytorch_lightning.trainer import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "model = instantiate_from_config(configs[0].model)\n",
        "model = model.to(\"cuda\")\n",
        "# model.logvar = model.logvar.to(\"cuda\")\n",
        "model.learning_rate = 1.0e-04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPor_IT5Zn4x",
        "outputId": "17882dc8-5251-4c1f-c513-660093fc2dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### Data #####\n",
            "train, KvasirSegTrain, 28\n",
            "validation, KvasirSegEval, 7\n"
          ]
        }
      ],
      "source": [
        "# data loader setup\n",
        "data = instantiate_from_config(configs[0].data)\n",
        "data.prepare_data()\n",
        "data.setup()\n",
        "print(\"#### Data #####\")\n",
        "for k in data.datasets:\n",
        "    print(f\"{k}, {data.datasets[k].__class__.__name__}, {len(data.datasets[k])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-o4hVAxKoIi",
        "outputId": "8437e05e-c032-4c8d-ef51-c817b0bf2de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnYGLMGIeFOp",
        "outputId": "1b9dd6d1-2e5a-4714-872b-f8d0bf564ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ],
      "source": [
        "saving_ckpt_path = \"/content/\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=saving_ckpt_path,  # Directory to save checkpoints\n",
        "    filename='latent_diffusion',  # Filename format\n",
        "    monitor='val/loss',  # Metric to monitor\n",
        "    mode='min',          # Mode for monitoring ('min' or 'max')\n",
        "    save_top_k=3         # Number of top models to save\n",
        ")\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     accelerator=\"gpu\",\n",
        "#     devices=1,\n",
        "#     strategy=None,\n",
        "#     max_epochs=1000,\n",
        "#     callbacks=[checkpoint_callback]\n",
        "# )\n",
        "\n",
        "trainer = Trainer(\n",
        "    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices     = 1,              # 또는 devices=[0]\n",
        "    # strategy    = None,         # None 대신 \"auto\"\n",
        "    max_epochs  = 1000,\n",
        "    callbacks   = [checkpoint_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "59f0a472d5934155a1d30c3de82d556f",
            "c6f07654308c4223a241114fb2bdd6de"
          ]
        },
        "id": "k-V6ZT19eY3B",
        "outputId": "5165f376-a288-4ec2-9961-be30bac5c911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return _C._get_float32_matmul_precision()\n",
            "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /content exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ first_stage_model │ VQModelInterface │ 55.3 M │ eval  │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ model             │ LightningDiT     │  457 M │ train │     0 │\n",
              "└───┴───────────────────┴──────────────────┴────────┴───────┴───────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ first_stage_model │ VQModelInterface │ 55.3 M │ eval  │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ model             │ LightningDiT     │  457 M │ train │     0 │\n",
              "└───┴───────────────────┴──────────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 456 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 55.6 M                                                                                       \n",
              "\u001b[1mTotal params\u001b[0m: 512 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2.0 K                                                                      \n",
              "\u001b[1mModules in train mode\u001b[0m: 424                                                                                         \n",
              "\u001b[1mModules in eval mode\u001b[0m: 174                                                                                          \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 456 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 55.6 M                                                                                       \n",
              "<span style=\"font-weight: bold\">Total params</span>: 512 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2.0 K                                                                      \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 424                                                                                         \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 174                                                                                          \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59f0a472d5934155a1d30c3de82d556f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPL87_6PKoIj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59f0a472d5934155a1d30c3de82d556f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c6f07654308c4223a241114fb2bdd6de",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "c6f07654308c4223a241114fb2bdd6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}